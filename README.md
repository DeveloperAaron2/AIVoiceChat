ğŸ™ï¸ VoiceChat AI â€“ Asistente de voz inteligente con Flask + Angular

VoiceChat AI es una aplicaciÃ³n completa (frontend + backend) que permite mantener una conversaciÃ³n natural por voz con un modelo de lenguaje local (LM Studio o DeepSeek).
El usuario habla â†’ el sistema transcribe el audio â†’ genera una respuesta con IA â†’ la devuelve en audio y texto al chat web.

ğŸš€ CaracterÃ­sticas principales
ğŸ§  Backend (Flask)

Reconocimiento de voz (STT) usando faster-whisper
 para transcribir el audio del usuario.

GeneraciÃ³n de respuesta con IA a travÃ©s de una API local (por ejemplo, LM Studio o DeepSeek-V3).

ConversiÃ³n de texto a voz (TTS) con edge-tts
 y cachÃ© local de archivos .mp3.

API REST con endpoints:

POST /stt â†’ convierte audio (.webm/.wav) en respuesta de voz.

POST /tts â†’ genera voz a partir de texto.

GET /media/<id>.mp3 â†’ sirve los audios cacheados.

CORS habilitado para integraciÃ³n directa con el frontend.

Compatibilidad con GPU (CUDA) opcional para acelerar Whisper.

ğŸ’» Frontend (Angular 17)

Interfaz tipo chat con mensajes de audio y texto.

GrabaciÃ³n directa desde el micrÃ³fono mediante MediaRecorder.

ReproducciÃ³n automÃ¡tica de las respuestas del asistente.

Indicadores visuales:

Loader â€œEnviandoâ€¦â€ mientras se procesa la peticiÃ³n.

Mensaje de estado mientras el backend genera la respuesta.

Arquitectura reactiva con signals (@if, @for, etc. de Angular 17).

DiseÃ±o limpio con TailwindCSS.

ğŸ§© Estructura del proyecto
VoiceChatAI/
â”‚
â”œâ”€â”€ frontend/                 # Angular 17 app
â”‚   â”œâ”€â”€ src/app/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ pages/
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                # Servidor Flask principal
â”‚   â”œâ”€â”€ analisisvoz.py        # LÃ³gica STT + TTS + LLM
â”‚   â”œâ”€â”€ tts_cache/            # Carpeta donde se guardan los .mp3
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env
â”‚
â””â”€â”€ README.md

âš™ï¸ InstalaciÃ³n
ğŸ”¹ Backend (Flask)
# Crear entorno
conda create -n voicechat python=3.10
conda activate voicechat

# Instalar dependencias
pip install -r requirements.txt

# (opcional) Instalar ffmpeg si no lo tienes
conda install -c conda-forge ffmpeg

# Iniciar servidor
python app.py


El backend correrÃ¡ en http://localhost:8000.

ğŸ”¹ Frontend (Angular)
cd frontend
npm install
ng serve


El frontend se servirÃ¡ en http://localhost:4200.

ğŸ—£ï¸ Flujo de funcionamiento

El usuario graba un audio en el navegador.

El frontend envÃ­a el Blob al backend (/stt).

Flask:

Convierte el audio a WAV (ffmpeg).

Lo transcribe con Whisper.

EnvÃ­a el texto al modelo de LM Studio.

Genera una respuesta hablada con Edge TTS.

El frontend recibe el .mp3 resultante y lo reproduce en el chat.

ğŸ§  TecnologÃ­as utilizadas
CategorÃ­a	Herramienta
Frontend	Angular 17, TypeScript, TailwindCSS
Backend	Flask, Flask-CORS
STT	faster-whisper
TTS	edge-tts, pyttsx3
AI	LM Studio / DeepSeek
Audio	ffmpeg, pydub
Infraestructura	Python 3.10+, Conda
ğŸ“¦ PrÃ³ximas mejoras

Soporte multilenguaje (en-US, es-ES, pt-BR).

Persistencia de historial de conversaciÃ³n.

SelecciÃ³n de voz TTS y velocidad desde el frontend.

Compatibilidad con APIs externas (OpenAI, Gemini...).

ğŸ§‘â€ğŸ’» Autor

AarÃ³n Borrego
Desarrollador full stack â€¢ IA, voz e interfaces naturales
ğŸ“§ borregomagantoaaron@gmail.com
